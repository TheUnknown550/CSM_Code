{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths and parameters\n",
    "win_size = 1024\n",
    "hop_size = win_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to hold training data\n",
    "stft_mag_train = []\n",
    "stft_noise_mag_train = []\n",
    "stft_mag_target_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim audiofile\n",
    "def trim_wav( originalWavPath,Name):\n",
    "    sampleRate, waveData = wavfile.read( originalWavPath )\n",
    "    startSample = int( 0 * sampleRate )\n",
    "    endSample = int( 10 * sampleRate )\n",
    "    wavfile.write( Name, sampleRate, waveData[startSample:endSample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "0 20\n",
      "1 10\n",
      "1 20\n",
      "2 10\n",
      "2 20\n",
      "3 10\n",
      "3 20\n",
      "4 10\n",
      "4 20\n",
      "5 10\n",
      "5 20\n",
      "6 10\n",
      "6 20\n",
      "7 10\n",
      "7 20\n",
      "8 10\n",
      "8 20\n",
      "9 10\n",
      "9 20\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10  # Define batch size\n",
    "\n",
    "# Define generator function to yield batches of audio files\n",
    "def audio_generator(batch_size):\n",
    "    for batch_start in range(0, 20, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, 250)\n",
    "        batch = []\n",
    "        for FileNum in range(batch_start, batch_end):\n",
    "            # Load the Audio File\n",
    "            audio_file = f'C:/Users/Matt/Documents/Project/CS-M/Experiments/NoiseCancelTests/Datasets/Original/All/({FileNum+1}).wav'\n",
    "            audio, sr = librosa.load(audio_file, sr=None)\n",
    "            batch.append(audio)\n",
    "        yield batch, sr, batch_start, batch_end\n",
    "\n",
    "# Loop over generator to add noise and extract features\n",
    "for NoiseNum in range(10):\n",
    "    for audio_batch, sr, batch_start, batch_end in audio_generator(batch_size):\n",
    "        # Noise files\n",
    "        noise_file = f'C:/Users/Matt/Documents/Project/CS-M/Experiments/NoiseCancelTests/Datasets/Noise/({NoiseNum+1}).wav'\n",
    "        noise, sr = librosa.load(noise_file, sr=None)\n",
    "\n",
    "        # Resize the noise array to match the length of the audio arrays in the batch\n",
    "        for i in range(len(audio_batch)):\n",
    "            if len(noise) > len(audio_batch[i]):\n",
    "                noise_batch = noise[:len(audio_batch[i])]\n",
    "            else:\n",
    "                audio_batch[i] = audio_batch[i][:len(noise)]\n",
    "                noise_batch = noise\n",
    "            audio_batch[i] = audio_batch[i] + noise_batch\n",
    "\n",
    "        # Extract features using Short-Time Fourier Transform (STFT)\n",
    "        stft_audio = librosa.stft(np.concatenate(audio_batch), n_fft=win_size, hop_length=hop_size)\n",
    "        stft_noise = librosa.stft(np.tile(noise_batch, (len(audio_batch), 1)), n_fft=win_size, hop_length=hop_size)\n",
    "\n",
    "        # Separate magnitude and phase components\n",
    "        stft_mag = np.abs(stft_audio)\n",
    "        stft_phase = np.angle(stft_audio)\n",
    "        stft_noise_mag = np.abs(stft_noise)\n",
    "\n",
    "        # Split processed features and target values into individual arrays\n",
    "        stft_mag_split = np.array_split(stft_mag, len(audio_batch))\n",
    "        stft_noise_mag_split = np.array_split(stft_noise_mag, len(audio_batch))\n",
    "\n",
    "        # Append processed features and target values to arrays\n",
    "        stft_mag_train.extend(stft_mag_split)\n",
    "        stft_noise_mag_train.extend(stft_noise_mag_split)\n",
    "        stft_mag_target_train.extend(stft_mag_split)\n",
    "        print(NoiseNum, batch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training data from all files\n",
    "stft_mag_train = np.concatenate(stft_mag_train, axis=0)\n",
    "stft_noise_mag_train = np.concatenate(stft_noise_mag_train, axis=0)\n",
    "stft_mag_target_train = np.concatenate(stft_mag_target_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.1 GiB for an array with shape (4598942400, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Reshape stft_noise_mag_train to have the same shape as reshaped_chunks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m reshaped_noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(stft_noise_mag_train, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m reshaped_noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mtile(reshaped_noise, (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(reshaped_chunks)))\n\u001b[0;32m     21\u001b[0m \u001b[39m# Concatenate reshaped_chunks and reshaped_noise along the second dimension\u001b[39;00m\n\u001b[0;32m     22\u001b[0m combined_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((reshaped_chunks \u001b[39m+\u001b[39m [reshaped_noise]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Matt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\shape_base.py:1278\u001b[0m, in \u001b[0;36mtile\u001b[1;34m(A, reps)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[39mfor\u001b[39;00m dim_in, nrep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(c\u001b[39m.\u001b[39mshape, tup):\n\u001b[0;32m   1277\u001b[0m         \u001b[39mif\u001b[39;00m nrep \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1278\u001b[0m             c \u001b[39m=\u001b[39m c\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, n)\u001b[39m.\u001b[39;49mrepeat(nrep, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1279\u001b[0m         n \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m=\u001b[39m dim_in\n\u001b[0;32m   1280\u001b[0m \u001b[39mreturn\u001b[39;00m c\u001b[39m.\u001b[39mreshape(shape_out)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.1 GiB for an array with shape (4598942400, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "# Define RNN model with LSTM layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), return_sequences=True))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(units=1, activation='linear')))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Split stft_mag_train into chunks with the same shape as stft_noise_mag_train\n",
    "chunk_size = stft_noise_mag_train.shape[0]\n",
    "chunks = [stft_mag_train[i:i+chunk_size] for i in range(0, len(stft_mag_train), chunk_size)]\n",
    "\n",
    "# Reshape chunks to have the same shape as stft_noise_mag_train\n",
    "reshaped_chunks = [np.expand_dims(chunk, axis=-1) for chunk in chunks]\n",
    "\n",
    "# Reshape stft_noise_mag_train to have the same shape as reshaped_chunks\n",
    "reshaped_noise = np.expand_dims(stft_noise_mag_train, axis=-1)\n",
    "reshaped_noise = np.tile(reshaped_noise, (1, 1, len(reshaped_chunks)))\n",
    "\n",
    "# Concatenate reshaped_chunks and reshaped_noise along the second dimension\n",
    "combined_input = np.concatenate((reshaped_chunks + [reshaped_noise]), axis=1)\n",
    "\n",
    "# Train model on combined input\n",
    "model.fit(combined_input, stft_mag_target_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = load_model('ANC.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_file = ''\n",
    "trim_wav(Test_file,'TestFile.wav')\n",
    "noise_file = ''\n",
    "trim_wav(noise_file,'noiseFile.wav')\n",
    "Test, sr = librosa.load('TestFile.wav', sr=None)\n",
    "noise, sr = librosa.load('noiseFile.wav', sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using STFT\n",
    "stft_test_audio = librosa.stft(Test, n_fft=win_size, hop_length=hop_size)\n",
    "stft_noise_audio = librosa.stft(noise, n_fft=win_size, hop_length=hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate magnitude and phase components\n",
    "stft_test_mag = np.abs(stft_test_audio)\n",
    "stft_test_phase = np.angle(stft_test_audio)\n",
    "stft_noise_mag = np.abs(stft_noise_audio)\n",
    "\n",
    "# Reshape magnitude component to (n_frames, n_bins) format\n",
    "test_mag_shape = stft_test_mag.shape\n",
    "stft_test_mag = np.reshape(stft_test_mag, (test_mag_shape[0], test_mag_shape[1], 1))\n",
    "noise_mag_shape = stft_noise_mag.shape\n",
    "stft_noise_mag = np.reshape(stft_noise_mag, (noise_mag_shape[0], noise_mag_shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to test audio\n",
    "stft_test_mag_pred = model.predict(np.concatenate((stft_test_mag, stft_noise_mag), axis=-1))\n",
    "stft_test_mag_pred = np.squeeze(stft_test_mag_pred, axis=-1)\n",
    "\n",
    "# Invert STFT to obtain noise-reduced audio\n",
    "stft_test_pred = stft_test_mag_pred * np.exp(1j * stft_test_phase)\n",
    "test_audio_pred = librosa.istft(stft_test_pred, hop_length=hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save noise-reduced audio to file\n",
    "librosa.output.write_wav('ANC.wav', test_audio_pred, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a65ab8ed40a82036885d05f93723ec9c2b91e509340366b1d5128ec98f6cb4c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
