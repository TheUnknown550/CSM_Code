{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tempfile as tmp\n",
    "import soundfile as sf\n",
    "from scipy import signal, stats\n",
    "from scipy.io import wavfile\n",
    "from typing import Tuple, Union\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, utils\n",
    "from tensorflow_addons import activations as tfa_activations\n",
    "from keras_nlp import layers as nlp_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_3048\\2002002543.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  (sampling_rate, wave_data) = wavfile.read(filename=path)\n"
     ]
    }
   ],
   "source": [
    "def trim_wav_file(path: str, st: int = 0, ed: int = 10) -> np.ndarray:\n",
    "    (sampling_rate, wave_data) = wavfile.read(filename=path)\n",
    "    st_sample: int = int(st * sampling_rate)\n",
    "    ed_sample: int = int(ed * sampling_rate)\n",
    "    wave_data = wave_data[st_sample:ed_sample]\n",
    "    del st_sample, ed_sample\n",
    "    return wave_data\n",
    "\n",
    "def get_signal_list(path: str) -> list[np.ndarray]:\n",
    "    file_names: list[str] = glob.glob(pathname=f\"{path}/*.wav\")\n",
    "    sample_list: list[np.ndarray] = []\n",
    "    for file_name in file_names:\n",
    "        sample: np.ndarray = trim_wav_file(path=file_name, st=0, ed=10)\n",
    "        sample_list.append(sample)\n",
    "        del sample\n",
    "    del file_name, file_names\n",
    "    return sample_list\n",
    "\n",
    "def combine_signal_list(signal_list: list[np.ndarray], mn_len: int) -> np.ndarray:\n",
    "    sample_list: list[np.ndarray] = []\n",
    "    for sgnal in signal_list:\n",
    "        sample_list.append(sgnal[:mn_len])\n",
    "    del sgnal\n",
    "    return np.stack(sample_list, axis=0)\n",
    "\n",
    "orig_list: list[np.ndarray] = get_signal_list(path=\"Dataset/Signal\")\n",
    "noise_list: list[np.ndarray] = get_signal_list(path=\"Dataset/Noise\")\n",
    "\n",
    "mn: int = 1e9\n",
    "for orig in orig_list:\n",
    "    mn = min(mn, orig.shape[0])\n",
    "del orig\n",
    "for noise in noise_list:\n",
    "    mn = min(mn, noise.shape[0])\n",
    "del noise\n",
    "\n",
    "orig: np.ndarray = combine_signal_list(orig_list, mn)\n",
    "noise: np.ndarray = combine_signal_list(noise_list, mn)[:, :, 0]\n",
    "del mn, orig_list, noise_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = signal.resample_poly(orig, up=1, down=3, axis=1)\n",
    "noise = signal.resample(noise, num=1898, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x_y_div(orig: np.ndarray, noise: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    x_list: list[np.ndarray] = []\n",
    "    y_list: list[np.ndarray] = []\n",
    "    x_avg_list: list[np.ndarray] = []\n",
    "    x_sd_list: list[np.ndarray] = []\n",
    "    for i in range(0, orig.shape[0]):\n",
    "        for j in range(0, noise.shape[0]):\n",
    "            combi: np.ndarray = orig[i] + noise[j]\n",
    "            x_list.append(np.stack([combi, noise[j]], axis=1))\n",
    "            x_avg_list.append(np.stack([np.average(combi, axis=0), np.average(noise[j], axis=0)], axis=0)[np.newaxis, :])\n",
    "            x_sd_list.append(np.stack([np.std(combi, axis=0), np.std(noise[j], axis=0)], axis=0)[np.newaxis, :])\n",
    "            y_list.append(orig[i])\n",
    "            del combi\n",
    "        del j\n",
    "    del i\n",
    "    x: np.ndarray = np.stack(x_list, axis=0)\n",
    "    y: np.ndarray = np.stack(y_list, axis=0)\n",
    "    x_avg: np.ndarray = np.stack(x_avg_list, axis=0)\n",
    "    x_sd: np.ndarray = np.stack(x_sd_list, axis=0)\n",
    "    return (x, y, x_avg, x_sd)\n",
    "\n",
    "(x, y, x_avg, x_sd) = gen_x_y_div(orig, noise)\n",
    "x = (x - x_avg) / x_sd\n",
    "y = (y - x_avg[:, :, 0]) / x_sd[:, :, 0]\n",
    "y = y[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_test, y_train, y_test) = model_selection.train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 29s 1s/step - loss: 0.7260 - MSE: 0.7260 - val_loss: 0.6598 - val_MSE: 0.6598\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7253 - MSE: 0.7253 - val_loss: 0.6591 - val_MSE: 0.6591\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7246 - MSE: 0.7246 - val_loss: 0.6586 - val_MSE: 0.6586\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7241 - MSE: 0.7241 - val_loss: 0.6581 - val_MSE: 0.6581\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7237 - MSE: 0.7237 - val_loss: 0.6577 - val_MSE: 0.6577\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7233 - MSE: 0.7233 - val_loss: 0.6573 - val_MSE: 0.6573\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7229 - MSE: 0.7229 - val_loss: 0.6569 - val_MSE: 0.6569\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.7225 - MSE: 0.7225 - val_loss: 0.6565 - val_MSE: 0.6565\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7222 - MSE: 0.7222 - val_loss: 0.6562 - val_MSE: 0.6562\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7218 - MSE: 0.7218 - val_loss: 0.6558 - val_MSE: 0.6558\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7215 - MSE: 0.7215 - val_loss: 0.6555 - val_MSE: 0.6555\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7212 - MSE: 0.7212 - val_loss: 0.6553 - val_MSE: 0.6553\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7209 - MSE: 0.7209 - val_loss: 0.6550 - val_MSE: 0.6550\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7206 - MSE: 0.7206 - val_loss: 0.6547 - val_MSE: 0.6547\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7204 - MSE: 0.7204 - val_loss: 0.6544 - val_MSE: 0.6544\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7201 - MSE: 0.7201 - val_loss: 0.6541 - val_MSE: 0.6541\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7198 - MSE: 0.7198 - val_loss: 0.6539 - val_MSE: 0.6539\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7196 - MSE: 0.7196 - val_loss: 0.6537 - val_MSE: 0.6537\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7195 - MSE: 0.7195 - val_loss: 0.6536 - val_MSE: 0.6536\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7194 - MSE: 0.7194 - val_loss: 0.6534 - val_MSE: 0.6534\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7192 - MSE: 0.7192 - val_loss: 0.6532 - val_MSE: 0.6532\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7190 - MSE: 0.7190 - val_loss: 0.6530 - val_MSE: 0.6530\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7188 - MSE: 0.7188 - val_loss: 0.6529 - val_MSE: 0.6529\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7187 - MSE: 0.7187 - val_loss: 0.6527 - val_MSE: 0.6527\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7185 - MSE: 0.7185 - val_loss: 0.6526 - val_MSE: 0.6526\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7184 - MSE: 0.7184 - val_loss: 0.6525 - val_MSE: 0.6525\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7183 - MSE: 0.7183 - val_loss: 0.6523 - val_MSE: 0.6523\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7182 - MSE: 0.7182 - val_loss: 0.6522 - val_MSE: 0.6522\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7181 - MSE: 0.7181 - val_loss: 0.6521 - val_MSE: 0.6521\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7180 - MSE: 0.7180 - val_loss: 0.6520 - val_MSE: 0.6520\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7179 - MSE: 0.7179 - val_loss: 0.6519 - val_MSE: 0.6519\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7178 - MSE: 0.7178 - val_loss: 0.6519 - val_MSE: 0.6519\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7177 - MSE: 0.7177 - val_loss: 0.6518 - val_MSE: 0.6518\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7176 - MSE: 0.7176 - val_loss: 0.6517 - val_MSE: 0.6517\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7176 - MSE: 0.7176 - val_loss: 0.6516 - val_MSE: 0.6516\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.7175 - MSE: 0.7175 - val_loss: 0.6516 - val_MSE: 0.6516\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7175 - MSE: 0.7175 - val_loss: 0.6515 - val_MSE: 0.6515\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7174 - MSE: 0.7174 - val_loss: 0.6514 - val_MSE: 0.6514\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7173 - MSE: 0.7173 - val_loss: 0.6514 - val_MSE: 0.6514\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7173 - MSE: 0.7173 - val_loss: 0.6513 - val_MSE: 0.6513\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7172 - MSE: 0.7172 - val_loss: 0.6513 - val_MSE: 0.6513\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7172 - MSE: 0.7172 - val_loss: 0.6512 - val_MSE: 0.6512\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7171 - MSE: 0.7171 - val_loss: 0.6512 - val_MSE: 0.6512\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7171 - MSE: 0.7171 - val_loss: 0.6511 - val_MSE: 0.6511\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7171 - MSE: 0.7171 - val_loss: 0.6511 - val_MSE: 0.6511\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7170 - MSE: 0.7170 - val_loss: 0.6511 - val_MSE: 0.6511\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7170 - MSE: 0.7170 - val_loss: 0.6510 - val_MSE: 0.6510\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7170 - MSE: 0.7170 - val_loss: 0.6510 - val_MSE: 0.6510\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7170 - MSE: 0.7170 - val_loss: 0.6510 - val_MSE: 0.6510\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7170 - MSE: 0.7170 - val_loss: 0.6510 - val_MSE: 0.6510\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6510 - val_MSE: 0.6510\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6510 - val_MSE: 0.6510\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7169 - MSE: 0.7169 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6509 - val_MSE: 0.6509\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6508 - val_MSE: 0.6508\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.7168 - MSE: 0.7168 - val_loss: 0.6507 - val_MSE: 0.6507\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.6873 - MSE: 0.6873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6872627139091492, 0.6872626543045044]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_trans() -> keras.Model:\n",
    "    inputs = keras.Input(x.shape[1:])\n",
    "    m = inputs\n",
    "    emb = nlp_layers.PositionEmbedding(sequence_length=x.shape[1])(m)\n",
    "    m = layers.Add()([m, emb])\n",
    "    m = nlp_layers.TransformerEncoder(intermediate_dim=2, num_heads=2, dropout=0, activation=\"relu\")(m)\n",
    "    m = nlp_layers.TransformerDecoder(intermediate_dim=2, num_heads=2, dropout=0, activation=\"relu\")(m)\n",
    "    m = layers.Dense(units=2, activation=tfa_activations.mish)(m)\n",
    "    m = layers.Dense(units=2, activation=tfa_activations.mish)(m)\n",
    "    m = layers.Dense(units=1, activation=\"linear\")(m)\n",
    "    outputs = m\n",
    "    base_model = keras.Model(inputs, outputs)\n",
    "    custom_objs: dict = {\n",
    "        \"keras_nlp>PositionEmbedding\": nlp_layers.PositionEmbedding,\n",
    "        \"keras_nlp>TransformerEncoder\": nlp_layers.TransformerEncoder,\n",
    "        \"keras_nlp>TransformerDecoder\": nlp_layers.TransformerDecoder,\n",
    "        \"Addons>mish\": tfa_activations.mish,\n",
    "    }\n",
    "    with utils.custom_object_scope(custom_objs):\n",
    "        model = keras.models.clone_model(base_model)\n",
    "    return model\n",
    "\n",
    "model = build_trans()\n",
    "model.compile(\n",
    "    loss=\"MSE\",\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"MSE\"]\n",
    ")\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 6s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04510546],\n",
       "       [-0.04705388],\n",
       "       [ 0.04510548],\n",
       "       ...,\n",
       "       [ 0.04510546],\n",
       "       [ 0.04510546],\n",
       "       [ 0.04510546]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
